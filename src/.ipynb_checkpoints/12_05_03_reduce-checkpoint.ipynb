{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84d21cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 10:50:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/05 10:50:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "# 스파크 환경 설정 객체 생성\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"241205_03_reduce\")\n",
    "spark =SparkContext(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dcfa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#여러개의 값을 하나로 축약\n",
    "# RDD.reduce(<)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19fb0cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:274"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rdd= spark.parallelize([1,2,3,4,5])\n",
    "sample_rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6579dd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4f49e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rdd.reduce(add) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffda62c",
   "metadata": {},
   "source": [
    "# partition 이 나누어져 있을 때 \n",
    "\n",
    "lambda x,y : (x*2) +y\n",
    "\n",
    "1: x=1, y=2 >> (1*2)+2 =4\n",
    "2: x=4, y=3  >> (4*2) +3=1\n",
    "3: x=11, y=4 >>(11*2) +4 =26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e3b4147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rdd1= spark.parallelize([1,2,3,4]) #여기는 하나의 파티션 \n",
    "sample_rdd1.reduce(lambda x,y:(x*2)+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9aa25af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rdd1.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59d678d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [3, 4]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rdd2= spark.parallelize([1,2,3,4],2) #파티션 쪼개기 \n",
    "sample_rdd2.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8fd4073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rdd2.reduce(lambda x,y:(x*2)+y) #파티션 나눴을 떄 \n",
    "# 4 , 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e798a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#파티션 3개일 때 - 설명 참고 \n",
    "\n",
    "# x: p1 y:p2 p3:x,y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d621f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [2], [3, 4]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#파티션 3개일 때\n",
    "\n",
    "# x: p1 y:p2 p3:x,y \n",
    "sample_rdd3= spark.parallelize([1,2,3,4],3)\n",
    "sample_rdd3.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081bf5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7e936d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rdd3.reduce(lambda x,y:(x*2)+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eda438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98669fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#리듀스 연산은 순서 의존적 \n",
    "# 각 파티션 내에서 연산은 독립적으로 실행, 최종 결과는 파티션 간의 결과가 결합 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492f0681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "170faa85",
   "metadata": {},
   "source": [
    "###fold  연산 활용 \n",
    "'''\n",
    "\n",
    "fold( zeroValue, <func> )\n",
    "    '''\n",
    "    zeroValue:시작값 , 항등원 * 일 때 1, + 일 경우0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4cbb40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd4= spark.parallelize([2,3,4],4)  #비어있는 값없음 \n",
    "rdd4.reduce(lambda x,y:x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec8c50eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd4.fold(1, lambda x,y:x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f37a8ea2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can not reduce() empty RDD",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#오류상황 가정, 빈RDD\u001b[39;00m\n\u001b[1;32m      2\u001b[0m rdd5\u001b[38;5;241m=\u001b[39m  spark\u001b[38;5;241m.\u001b[39mparallelize([])  \n\u001b[0;32m----> 3\u001b[0m \u001b[43mrdd5\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb\u001b[49m\u001b[43m:\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/rdd.py:1000\u001b[0m, in \u001b[0;36mRDD.reduce\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vals:\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reduce(f, vals)\n\u001b[0;32m-> 1000\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not reduce() empty RDD\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Can not reduce() empty RDD"
     ]
    }
   ],
   "source": [
    "#오류상황 가정, 빈RDD\n",
    "rdd5=  spark.parallelize([])  \n",
    "rdd5.reduce(lambda a,b:a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4224c39f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spark_start)",
   "language": "python",
   "name": "spark_start"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
