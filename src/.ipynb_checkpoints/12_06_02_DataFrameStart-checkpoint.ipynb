{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7abaf7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "#r46p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55f9f3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/06 13:44:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/06 13:44:18 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "#singLenton pattern object builder \n",
    "from pyspark.sql import SparkSession\n",
    "spark= SparkSession.builder.appName(\"FirstSparkSessionApp\").getOrCreate()\n",
    "\n",
    "#이제 위에처럼 생성 안해도 됨. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f08cda0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "myRange= spark.range(1000) #parallelize 생성 안해도 됨. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ced3902a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab82bd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myRange.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed5488d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (\"Brook\",20),\n",
    "    (\"Denny\",20), \n",
    "    (\"Jules\",20),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5d3a286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_1: string, _2: bigint]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame= spark.createDataFrame(data)\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd764679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "|   _1| _2|\n",
      "+-----+---+\n",
      "|Brook| 20|\n",
      "|Denny| 20|\n",
      "|Jules| 20|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#row 객체 58p\n",
    "data_frame.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "080e095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.createOrReplaceTempView(\"people\") #임시 뷰 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4a7b108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| _1| _2|\n",
      "+---+---+\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result= spark.sql(\"select _1, _2 from people where _2> 30\") #문장으로 바로 구성 가능\n",
    "result.show( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f057a434",
   "metadata": {},
   "outputs": [],
   "source": [
    "#52 p StructType 구조 정의  /v파이썬 타입 참고 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4dd021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import*  #from pyspark.sql 앞으로 여기서 많이 사용할 것 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d070d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema= StructType(\n",
    "    [\n",
    "    StructField(\"Author\", StringType(), False),\n",
    "    StructField(\"age \", IntegerType(), False)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0823aef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(Author,StringType,false),StructField(age ,IntegerType,false)))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c7c143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_df= spark.createDataFrame(data, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c589559",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+\n",
      "|Author|age |\n",
      "+------+----+\n",
      "| Brook|  20|\n",
      "| Denny|  20|\n",
      "| Jules|  20|\n",
      "+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5794a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define schema for our data\n",
    "schema = StructType([\n",
    "   StructField(\"Id\", IntegerType(), False),\n",
    "   StructField(\"First\", StringType(), False),\n",
    "   StructField(\"Last\", StringType(), False),\n",
    "   StructField(\"Url\", StringType(), False),\n",
    "   StructField(\"Published\", StringType(), False),\n",
    "   StructField(\"Hits\", IntegerType(), False),\n",
    "   StructField(\"Campaigns\", ArrayType(StringType()), False)])\n",
    "\n",
    "#create our data\n",
    "data = [[1, \"Jules\", \"Damji\", \"https://tinyurl.1\", \"1/4/2016\", 4535, [\"twitter\", \"LinkedIn\"]],\n",
    "       [2, \"Brooke\",\"Wenig\",\"https://tinyurl.2\", \"5/5/2018\", 8908, [\"twitter\", \"LinkedIn\"]],\n",
    "       [3, \"Denny\", \"Lee\", \"https://tinyurl.3\",\"6/7/2019\",7659, [\"web\", \"twitter\", \"FB\", \"LinkedIn\"]],\n",
    "       [4, \"Tathagata\", \"Das\",\"https://tinyurl.4\", \"5/12/2018\", 10568, [\"twitter\", \"FB\"]],\n",
    "       [5, \"Matei\",\"Zaharia\", \"https://tinyurl.5\", \"5/14/2014\", 40578, [\"web\", \"twitter\", \"FB\", \"LinkedIn\"]],\n",
    "       [6, \"Reynold\", \"Xin\", \"https://tinyurl.6\", \"3/2/2015\", 25568, [\"twitter\", \"LinkedIn\"]]\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0fbc190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_df = spark.createDataFrame(data, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4adf7e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = false)\n",
      " |-- First: string (nullable = false)\n",
      " |-- Last: string (nullable = false)\n",
      " |-- Url: string (nullable = false)\n",
      " |-- Published: string (nullable = false)\n",
      " |-- Hits: integer (nullable = false)\n",
      " |-- Campaigns: array (nullable = false)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "b_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d8be9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| Id|\n",
      "+---+\n",
      "|  1|\n",
      "|  2|\n",
      "+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#column 별로 추출 \n",
    "b_df.select(\"Id\").show(2) #projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc71007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c389177a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|(Hits * 2)|\n",
      "+----------+\n",
      "|      9070|\n",
      "|     17816|\n",
      "|     15318|\n",
      "|     21136|\n",
      "|     81156|\n",
      "|     51136|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "b_df.select(expr(\"Hits\")*2).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f9a7ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|(Hits * 2)|\n",
      "+----------+\n",
      "|      9070|\n",
      "|     17816|\n",
      "|     15318|\n",
      "|     21136|\n",
      "|     81156|\n",
      "|     51136|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "b_df.select(col(\"Hits\")*2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ad2218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3709669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a377df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a53f5bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285baa9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac364ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ca0a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DDL 로 작성 P52\n",
    "\n",
    "schema = \"'Id' INT, 'First' STRING, 'Last' STRING, 'Url' STRING,\n",
    "''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7074f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee01cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#56P select 문 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceea35d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0c8f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b128c265",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop() # 항상 리소스 닫기 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spark_start)",
   "language": "python",
   "name": "spark_start"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
